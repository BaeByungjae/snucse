{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "신경망 학습\n",
    "========\n",
    "MNIST 이미지 인식 신경망을 역전파를 써서 만들어보자. 아래와 같은 구조로 만들것임.\n",
    "\n",
    "> 입력층(784) &rarr; 은닉층 &rarr; 시그모이드 &rarr; 결과(10) &rarr; 소프트맥스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시작!\n",
      "\n",
      "반복횟수\t정확도\tLoss\n",
      "-------------------------------------------\n",
      "       0\t14.0%\t2.3038295694064117\n",
      "     300\t60.0%\t1.5374030657050957\n",
      "     600\t83.0%\t0.6986352475785611\n",
      "     900\t80.0%\t0.5839718143466742\n",
      "    1200\t90.0%\t0.3980761341793732\n",
      "    1500\t92.0%\t0.35957619490559295\n",
      "    1800\t91.0%\t0.3813059236076406\n",
      "    2100\t97.0%\t0.21716477230783163\n",
      "    2400\t86.0%\t0.36983858549496623\n",
      "    2700\t93.0%\t0.24281726580553056\n",
      "    3000\t89.0%\t0.31989025317745745\n",
      "    3300\t92.0%\t0.36311490339430497\n",
      "    3600\t94.0%\t0.31396136521992446\n",
      "    3900\t93.0%\t0.2558455911821598\n",
      "    4200\t86.0%\t0.32691406575618215\n",
      "    4500\t91.0%\t0.2925008002107429\n",
      "    4800\t90.0%\t0.29249756723289705\n",
      "    5100\t94.0%\t0.25101859679622857\n",
      "    5400\t93.0%\t0.2510662758883689\n",
      "    5700\t89.0%\t0.26757411253411256\n",
      "    6000\t96.0%\t0.18355339708285953\n",
      "    6300\t85.0%\t0.4237913523903206\n",
      "    6600\t94.0%\t0.2295439851592964\n",
      "    6900\t96.0%\t0.13518225149769483\n",
      "    7200\t90.0%\t0.2397597220188128\n",
      "    7500\t93.0%\t0.2337063350708975\n",
      "    7800\t88.0%\t0.31823535296692324\n",
      "    8100\t93.0%\t0.2003552067408656\n",
      "    8400\t97.0%\t0.10845716319598661\n",
      "    8700\t94.0%\t0.18032047909229582\n",
      "    9000\t98.0%\t0.08765612672782389\n",
      "    9300\t92.0%\t0.23696821215762395\n",
      "    9600\t95.0%\t0.1335263096645289\n",
      "    9900\t97.0%\t0.09628413111990294\n",
      "\n",
      "학습 완료!\n",
      "\n",
      "최종 점수\n",
      "-------------\n",
      "정확도 : 94.56%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import signal\n",
    "import sys\n",
    "import mnist\n",
    "from common import sigmoid, gradient_sigmoid, softmax, cross_entropy_error_batch\n",
    "\n",
    "#\n",
    "# Hyper parameters\n",
    "#\n",
    "# 히든레이어 뉴런 수 (ex: 50, 100)\n",
    "HIDDEN_LAYER_SIZE = 100\n",
    "# 정규분포 난수로 생성될 초기 가중치의 표준편차\n",
    "WEIGHT_INIT_STD = 0.01\n",
    "# 경사하강법을 몇번 적용할지\n",
    "ITERATION_COUNT = 10000\n",
    "# 학습에 사용할 미니배치의 크기\n",
    "BATCH_SIZE = 100\n",
    "# 학습률\n",
    "LEARNING_RATE = 0.1\n",
    "# 에퍼크, 학습 진척도를 얼마나 자주 표시할지 (ex: 100, 300)\n",
    "EPOCH = 300\n",
    "\n",
    "#\n",
    "# Utility functions\n",
    "#\n",
    "def make_predict(input):\n",
    "    def predict(w0, b0, w1, b1):\n",
    "        a0 = input @ w0 + b0\n",
    "        z0 = sigmoid(a0)\n",
    "        a1 = z0 @ w1 + b1\n",
    "        z1 = softmax(a1)\n",
    "        return [a0, z0, a1, z1]\n",
    "    return predict\n",
    "\n",
    "def accuracy(expected, actual):\n",
    "    return (expected.argmax(axis=-1) == actual.argmax(axis=-1)).mean()\n",
    "\n",
    "#\n",
    "# Main logic\n",
    "#\n",
    "MNIST = mnist.load()\n",
    "TRAIN_IMG = MNIST['train_img']\n",
    "TRAIN_LABEL = MNIST['train_label']\n",
    "\n",
    "layer0_size = TRAIN_IMG.shape[-1]\n",
    "layer1_size = HIDDEN_LAYER_SIZE\n",
    "layer2_size = TRAIN_LABEL.shape[-1]\n",
    "\n",
    "# Randomly initialize the parameters\n",
    "parameters = [\n",
    "    # w0\n",
    "    WEIGHT_INIT_STD * np.random.randn(layer0_size, layer1_size), \n",
    "    # b0\n",
    "    np.zeros(layer1_size),\n",
    "    # w1\n",
    "    WEIGHT_INIT_STD * np.random.randn(layer1_size, layer2_size),\n",
    "    # b1\n",
    "    np.zeros(layer2_size),\n",
    "]\n",
    "\n",
    "print('''학습 시작!\n",
    "\n",
    "반복횟수\\t정확도\\tLoss\n",
    "-------------------------------------------''')\n",
    "for iteration in range(ITERATION_COUNT):\n",
    "    # Sample a batch from the train image/label set\n",
    "    sample = np.random.choice(TRAIN_IMG.shape[0], BATCH_SIZE)\n",
    "    BATCH_IMG = TRAIN_IMG[sample]\n",
    "    BATCH_LABEL = TRAIN_LABEL[sample]\n",
    "\n",
    "    predict = make_predict(BATCH_IMG)\n",
    "\n",
    "    # Try the result\n",
    "    if iteration % EPOCH == 0:\n",
    "        expected = predict(*parameters)[-1]\n",
    "        percentage = accuracy(expected, BATCH_LABEL)*100\n",
    "        loss = cross_entropy_error_batch(expected, BATCH_LABEL)\n",
    "        print(f'{iteration:8}\\t{percentage:.04}%\\t{loss}')\n",
    "\n",
    "    # Calculate gradient\n",
    "    def grad(parameters):\n",
    "        w1 = parameters[2]\n",
    "        a0, z0, _, expected = predict(*parameters)\n",
    "\n",
    "        # Backward propagation\n",
    "        dz1 = (expected - BATCH_LABEL)/BATCH_SIZE\n",
    "        dw1 = z0.T @ dz1\n",
    "        db1 = dz1.sum(axis=0)\n",
    "\n",
    "        dz0 = gradient_sigmoid(a0) * (dz1 @ w1.T)\n",
    "        dw0 = BATCH_IMG.T @ dz0\n",
    "        db0 = dz0.sum(axis=0)\n",
    "        return [dw0, db0, dw1, db1]\n",
    "\n",
    "    # Update parameters using gradient descent method\n",
    "    gradient = grad(parameters)\n",
    "    for param, grad in zip(parameters, gradient):\n",
    "        param -= LEARNING_RATE * grad\n",
    "\n",
    "expected = make_predict(MNIST['test_img'])(*parameters)[-1]\n",
    "TEST_LABEL = MNIST['test_label']\n",
    "percentage = accuracy(expected, TEST_LABEL)*100\n",
    "\n",
    "print(f'''\n",
    "학습 완료!\n",
    "\n",
    "최종 점수\n",
    "-------------\n",
    "정확도 : {percentage}%\n",
    "''')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
